{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "287057b7-0a6c-4a4c-a938-30ad8673bca2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMRequestsChain, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ea7fb6f-d95c-410d-a4c7-f20ed0e43ef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Between >>> and <<< are the raw search result text from google.\n",
    "Extract the answer to the question '{query}' or say \"not found\" if the information is not contained.\n",
    "Use the format\n",
    "Extracted:<answer or \"not found\">\n",
    ">>> {requests_result} <<<\n",
    "Extracted:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"query\", \"requests_result\"],\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "299930bf-f4bd-4eb5-bfd8-0991865f1f35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# !export https_proxy=http://proxy01.uniontech.com:3128\n",
    "# !export http_proxy=http://proxy01.uniontech.com:3128\n",
    "# os.environ['http_proxy'] = 'http://proxy01.uniontech.com:3128'\n",
    "# os.environ['https_proxy'] = 'http://proxy02.uniontech.com:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2da3f810-a0db-4db1-8670-9899b18fdb5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! api_base is not default parameter.\n",
      "                    api_base was transfered to model_kwargs.\n",
      "                    Please confirm that api_base is what you intended.\n",
      "WARNING! api_key is not default parameter.\n",
      "                    api_key was transfered to model_kwargs.\n",
      "                    Please confirm that api_key is what you intended.\n"
     ]
    }
   ],
   "source": [
    "OPENAI_API_BASE='https://newcon.space/v1'\n",
    "# llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", api_base=OPENAI_API_BASE, api_key = os.environ.get('OPENAI_API_KEY'))\n",
    "llm = OpenAI(temperature=0, api_base=OPENAI_API_BASE, api_key = os.environ.get('OPENAI_API_KEY'))\n",
    "chain = LLMRequestsChain(llm_chain = LLMChain(llm=llm, prompt=PROMPT), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "344ba127-a2b2-4503-a135-98d253fb1ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"What are the Three (3) biggest countries, and their respective sizes?\"\n",
    "inputs = {\n",
    "    \"query\": question,\n",
    "    \"url\": \"https://www.google.com/search?q=\" + question.replace(\" \", \"+\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde79cf4-76c6-4850-b10e-26a9fd63ec4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4162a7f-5ad3-43e8-ab68-fa0e7284bf13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://proxy01.uniontech.com:3128\n"
     ]
    }
   ],
   "source": [
    "!echo $HTTPS_PROXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d42cbbf-8acd-4169-8f63-ec1616edf06d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptenv",
   "language": "python",
   "name": "gptenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
